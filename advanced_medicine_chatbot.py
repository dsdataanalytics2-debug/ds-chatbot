#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ЁЯТК ржЙржирзНржиржд ржорзЗржбрж┐рж╕рж┐ржи ржЪрзНржпрж╛ржЯржмржЯ - ржмрж╛ржВрж▓рж╛ ржнрж╛рж╖рж╛ржпрж╝ рж╕ржорзНржкрзВрж░рзНржг рж╕ржорж░рзНржержи
PDF, Word, Excel, API рж╕ржорж░рзНржержи рж╕рж╣
"""

import streamlit as st
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import warnings
import requests
import json
from pathlib import Path
import io
import base64
from datetime import datetime
warnings.filterwarnings('ignore')

# PDF ржПржмржВ Word ржлрж╛ржЗрж▓ ржкрзНрж░рж╕рзЗрж╕рж┐ржВ ржПрж░ ржЬржирзНржп
try:
    import PyPDF2
    import docx
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False
    st.warning("PDF/Word рж╕ржорж░рзНржержирзЗрж░ ржЬржирзНржп PyPDF2 ржПржмржВ python-docx ржЗржирж╕рзНржЯрж▓ ржХрж░рзБржи")

# Download required NLTK data
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')

try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords')

class AdvancedMedicineChatbot:
    def __init__(self, excel_file):
        self.excel_file = excel_file
        self.data = None
        self.vectorizer = None
        self.tfidf_matrix = None
        self.pdf_data = []
        self.word_data = []
        self.excel_data = []
        self.api_data = []
        self.all_sources = []
        self.bengali_stop_words = set([
            'ржПржмржВ', 'ржЕржержмрж╛', 'ржХрж┐ржирзНрждрзБ', 'ржпржжрж┐', 'рждржмрзЗ', 'ржХрзЗржи', 'ржХрж┐ржнрж╛ржмрзЗ', 'ржХрзЛржерж╛ржпрж╝', 'ржХржЦржи', 
            'ржХрж┐', 'ржХрзЛржи', 'ржХрж╛ржжрзЗрж░', 'ржХрж╛рж░', 'ржХрж╛ржХрзЗ', 'ржХрж┐', 'ржХрж┐', 'ржХрж┐', 'ржХрж┐', 'ржХрж┐', 
            'рж╣ржпрж╝', 'рж╣ржпрж╝рзЗржЫрзЗ', 'рж╣ржмрзЗ', 'ржХрж░рждрзЗ', 'ржХрж░рзЗ', 'ржХрж░ржмрзЗ', 'ржЖржЫрзЗ', 'ржирзЗржЗ', 'ржерж╛ржХржмрзЗ',
            'ржПржЯрж╛', 'ржПржЯрж┐', 'рж╕рзЗржЯрж╛', 'рж╕рзЗржЯрж┐', 'ржПржЗ', 'рж╕рзЗржЗ', 'ржпрзЗ', 'ржпрж╛', 'ржпрж╛рж░', 'ржпрж╛ржжрзЗрж░',
            'ржЖржорж┐', 'ржЖржорж░рж╛', 'рждрзБржорж┐', 'рждрзЛржорж░рж╛', 'рж╕рзЗ', 'рждрж╛рж░рж╛', 'ржЖржкржирж┐', 'ржЖржкржирж╛рж░рж╛',
            'ржПржЦрж╛ржирзЗ', 'рж╕рзЗржЦрж╛ржирзЗ', 'ржпрзЗржЦрж╛ржирзЗ', 'ржХрзЛржерж╛ржпрж╝', 'ржХрзЛржерж╛ржУ', 'ржХрзЛржерж╛ржУ', 'ржХрзЛржерж╛ржУ',
            'ржПржЦржи', 'рждржЦржи', 'ржХржЦржи', 'рж╕ржмрж╕ржоржпрж╝', 'ржХржЦржиржУ', 'ржХржЦржиржУ', 'ржХржЦржиржУ', 'ржХржЦржиржУ',
            'ржнрж╛рж▓рзЛ', 'ржЦрж╛рж░рж╛ржк', 'ржмржбрж╝', 'ржЫрзЛржЯ', 'ржирждрзБржи', 'ржкрзБрж░рж╛ржирзЛ', 'рж╕рзБржирзНржжрж░', 'ржХрзБрзОрж╕рж┐ржд',
            'рж╕рж╣ржЬ', 'ржХржарж┐ржи', 'ржжрзНрж░рзБржд', 'ржзрзАрж░', 'ржЧрж░ржо', 'ржарж╛ржирзНржбрж╛', 'ржЙрж╖рзНржг', 'рж╢рзАрждрж▓'
        ])
        self.load_data()
        self.preprocess_data()
        
def save_uploaded_file_to_data_source(uploaded_file):
    """UploadedFile ржбрж┐рж╕рзНржХрзЗ рж╕рзЗржн ржХрж░рзБржи: ./data source/<timestamp>_<filename>"""
    try:
        data_dir = Path("data source")
        data_dir.mkdir(parents=True, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_name = uploaded_file.name
        dest_path = data_dir / f"{timestamp}_{safe_name}"
        try:
            bytes_data = uploaded_file.getbuffer()
            with open(dest_path, "wb") as f:
                f.write(bytes_data)
        except Exception:
            content = uploaded_file.read()
            with open(dest_path, "wb") as f:
                f.write(content)
            try:
                uploaded_file.seek(0)
            except Exception:
                pass
        return str(dest_path)
    except Exception as e:
        st.warning(f"ржлрж╛ржЗрж▓ рж╕рзЗржн ржХрж░рждрзЗ рж╕ржорж╕рзНржпрж╛: {e}")
        return ""

    def load_data(self):
        """Excel ржлрж╛ржЗрж▓ ржерзЗржХрзЗ ржбрзЗржЯрж╛ рж▓рзЛржб ржХрж░рзБржи"""
        try:
            self.data = pd.read_excel(self.excel_file)
            st.success(f"тЬЕ ржбрзЗржЯрж╛ рж╕ржлрж▓ржнрж╛ржмрзЗ рж▓рзЛржб рж╣ржпрж╝рзЗржЫрзЗ! ржорзЛржЯ {len(self.data)} ржЯрж┐ ржУрж╖рзБржз ржкрж╛ржУржпрж╝рж╛ ржЧрзЗржЫрзЗред")
        except Exception as e:
            st.error(f"тЭМ ржбрзЗржЯрж╛ рж▓рзЛржб ржХрж░рждрзЗ рж╕ржорж╕рзНржпрж╛ рж╣ржпрж╝рзЗржЫрзЗ: {str(e)}")
            return None
    
    def add_pdf_file(self, pdf_file):
        """PDF ржлрж╛ржЗрж▓ ржерзЗржХрзЗ ржЯрзЗржХрзНрж╕ржЯ ржПржХрзНрж╕ржЯрзНрж░рзНржпрж╛ржХрзНржЯ ржХрж░рзБржи"""
        if not PDF_AVAILABLE:
            st.error("тЭМ PDF рж╕ржорж░рзНржержи ржирзЗржЗред PyPDF2 ржЗржирж╕рзНржЯрж▓ ржХрж░рзБржиред")
            return False
            
        try:
            saved_path = save_uploaded_file_to_data_source(pdf_file)
            pdf_reader = PyPDF2.PdfReader(pdf_file)
            text_content = ""
            
            for page_num in range(len(pdf_reader.pages)):
                page = pdf_reader.pages[page_num]
                text_content += page.extract_text() + "\n"
            
            if text_content.strip():
                self.pdf_data.append({
                    'filename': pdf_file.name,
                    'content': text_content,
                    'source': 'PDF',
                    'upload_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    'saved_path': saved_path
                })
                st.success(f"тЬЕ PDF ржлрж╛ржЗрж▓ '{pdf_file.name}' рж╕ржлрж▓ржнрж╛ржмрзЗ ржпрзЛржЧ рж╣ржпрж╝рзЗржЫрзЗ")
                return True
            else:
                st.warning("тЪая╕П PDF ржлрж╛ржЗрж▓ ржерзЗржХрзЗ ржХрзЛржи ржЯрзЗржХрзНрж╕ржЯ ржкрж╛ржУржпрж╝рж╛ ржпрж╛ржпрж╝ржирж┐")
                return False
                
        except Exception as e:
            st.error(f"тЭМ PDF ржлрж╛ржЗрж▓ ржкрзНрж░рж╕рзЗрж╕ ржХрж░рждрзЗ рж╕ржорж╕рзНржпрж╛: {str(e)}")
            return False
    
    def add_word_file(self, word_file):
        """Word ржлрж╛ржЗрж▓ ржерзЗржХрзЗ ржЯрзЗржХрзНрж╕ржЯ ржПржХрзНрж╕ржЯрзНрж░рзНржпрж╛ржХрзНржЯ ржХрж░рзБржи"""
        if not PDF_AVAILABLE:
            st.error("тЭМ Word рж╕ржорж░рзНржержи ржирзЗржЗред python-docx ржЗржирж╕рзНржЯрж▓ ржХрж░рзБржиред")
            return False
            
        try:
            saved_path = save_uploaded_file_to_data_source(word_file)
            doc = docx.Document(word_file)
            text_content = ""
            
            for paragraph in doc.paragraphs:
                text_content += paragraph.text + "\n"
            
            if text_content.strip():
                self.word_data.append({
                    'filename': word_file.name,
                    'content': text_content,
                    'source': 'Word',
                    'upload_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    'saved_path': saved_path
                })
                st.success(f"тЬЕ Word ржлрж╛ржЗрж▓ '{word_file.name}' рж╕ржлрж▓ржнрж╛ржмрзЗ ржпрзЛржЧ рж╣ржпрж╝рзЗржЫрзЗ")
                return True
            else:
                st.warning("тЪая╕П Word ржлрж╛ржЗрж▓ ржерзЗржХрзЗ ржХрзЛржи ржЯрзЗржХрзНрж╕ржЯ ржкрж╛ржУржпрж╝рж╛ ржпрж╛ржпрж╝ржирж┐")
                return False
                
        except Exception as e:
            st.error(f"тЭМ Word ржлрж╛ржЗрж▓ ржкрзНрж░рж╕рзЗрж╕ ржХрж░рждрзЗ рж╕ржорж╕рзНржпрж╛: {str(e)}")
            return False
    
    def add_excel_file(self, excel_file):
        """Excel ржлрж╛ржЗрж▓ ржерзЗржХрзЗ ржбрзЗржЯрж╛ рж▓рзЛржб ржХрж░рзБржи"""
        try:
            saved_path = save_uploaded_file_to_data_source(excel_file)
            df = pd.read_excel(excel_file)
            
            if len(df) > 0:
                # Excel ржбрзЗржЯрж╛ржХрзЗ ржЯрзЗржХрзНрж╕ржЯрзЗ рж░рзВржкрж╛ржирзНрждрж░ ржХрж░рзБржи
                text_content = ""
                for idx, row in df.iterrows():
                    row_text = " ".join([str(val) for val in row.values if pd.notna(val)])
                    text_content += row_text + "\n"
                
                self.excel_data.append({
                    'filename': excel_file.name,
                    'content': text_content,
                    'dataframe': df,
                    'source': 'Excel',
                    'upload_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    'saved_path': saved_path
                })
                st.success(f"тЬЕ Excel ржлрж╛ржЗрж▓ '{excel_file.name}' рж╕ржлрж▓ржнрж╛ржмрзЗ ржпрзЛржЧ рж╣ржпрж╝рзЗржЫрзЗ ({len(df)} рж╕рж╛рж░рж┐)")
                return True
            else:
                st.warning("тЪая╕П Excel ржлрж╛ржЗрж▓рзЗ ржХрзЛржи ржбрзЗржЯрж╛ ржирзЗржЗ")
                return False
                
        except Exception as e:
            st.error(f"тЭМ Excel ржлрж╛ржЗрж▓ ржкрзНрж░рж╕рзЗрж╕ ржХрж░рждрзЗ рж╕ржорж╕рзНржпрж╛: {str(e)}")
            return False
    
    def add_api_data(self, api_url, api_key=None):
        """API ржерзЗржХрзЗ ржбрзЗржЯрж╛ рж╕ржВржЧрзНрж░рж╣ ржХрж░рзБржи"""
        try:
            headers = {}
            if api_key:
                headers['Authorization'] = f'Bearer {api_key}'
                headers['X-API-Key'] = api_key
            
            response = requests.get(api_url, headers=headers, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            
            # API ржбрзЗржЯрж╛ржХрзЗ ржЯрзЗржХрзНрж╕ржЯрзЗ рж░рзВржкрж╛ржирзНрждрж░ ржХрж░рзБржи
            text_content = json.dumps(data, indent=2, ensure_ascii=False)
            
            self.api_data.append({
                'url': api_url,
                'content': text_content,
                'raw_data': data,
                'source': 'API',
                'upload_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'status': 'success'
            })
            
            st.success(f"тЬЕ API ржбрзЗржЯрж╛ рж╕ржлрж▓ржнрж╛ржмрзЗ ржпрзЛржЧ рж╣ржпрж╝рзЗржЫрзЗ")
            return True
            
        except requests.exceptions.RequestException as e:
            st.error(f"тЭМ API ржХрж▓ ржХрж░рждрзЗ рж╕ржорж╕рзНржпрж╛: {str(e)}")
            return False
        except json.JSONDecodeError:
            st.error("тЭМ API ржерзЗржХрзЗ JSON ржбрзЗржЯрж╛ ржкрж╛ржУржпрж╝рж╛ ржпрж╛ржпрж╝ржирж┐")
            return False
        except Exception as e:
            st.error(f"тЭМ API ржбрзЗржЯрж╛ ржкрзНрж░рж╕рзЗрж╕ ржХрж░рждрзЗ рж╕ржорж╕рзНржпрж╛: {str(e)}")
            return False
    
    def update_all_sources(self):
        """рж╕ржм ржЙрзОрж╕рзЗрж░ ржбрзЗржЯрж╛ ржПржХрждрзНрж░рж┐ржд ржХрж░рзБржи"""
        self.all_sources = []
        
        # ржорзВрж▓ Excel ржбрзЗржЯрж╛ ржпрзЛржЧ ржХрж░рзБржи
        if self.data is not None:
            for idx, row in self.data.iterrows():
                self.all_sources.append({
                    'source': 'Main Excel',
                    'filename': self.excel_file,
                    'content': ' '.join([str(val) for val in row.values if pd.notna(val)]),
                    'row_index': idx,
                    'data': row.to_dict()
                })
        
        # ржЖржкрж▓рзЛржб ржХрж░рж╛ Excel ржбрзЗржЯрж╛ ржпрзЛржЧ ржХрж░рзБржи
        for excel_item in self.excel_data:
            for idx, row in excel_item['dataframe'].iterrows():
                self.all_sources.append({
                    'source': 'Uploaded Excel',
                    'filename': excel_item['filename'],
                    'content': ' '.join([str(val) for val in row.values if pd.notna(val)]),
                    'row_index': idx,
                    'data': row.to_dict(),
                    'upload_time': excel_item['upload_time']
                })
        
        # PDF ржбрзЗржЯрж╛ ржпрзЛржЧ ржХрж░рзБржи
        for pdf_item in self.pdf_data:
            self.all_sources.append({
                'source': 'PDF',
                'filename': pdf_item['filename'],
                'content': pdf_item['content'],
                'upload_time': pdf_item['upload_time']
            })
        
        # Word ржбрзЗржЯрж╛ ржпрзЛржЧ ржХрж░рзБржи
        for word_item in self.word_data:
            self.all_sources.append({
                'source': 'Word',
                'filename': word_item['filename'],
                'content': word_item['content'],
                'upload_time': word_item['upload_time']
            })
        
        # API ржбрзЗржЯрж╛ ржпрзЛржЧ ржХрж░рзБржи
        for api_item in self.api_data:
            self.all_sources.append({
                'source': 'API',
                'url': api_item['url'],
                'content': api_item['content'],
                'upload_time': api_item['upload_time']
            })
    
    def preprocess_data(self):
        """рж╕рж╛рж░рзНржЪрзЗрж░ ржЬржирзНржп ржбрзЗржЯрж╛ ржкрзНрж░рж┐ржкрзНрж░рж╕рзЗрж╕ ржХрж░рзБржи"""
        if self.data is None:
            return
            
        # рж╕ржм ржЯрзЗржХрзНрж╕ржЯ ржХрж▓рж╛ржо ржЦрзБржБржЬрзЗ ржмрзЗрж░ ржХрж░рзБржи
        text_columns = []
        for col in self.data.columns:
            if self.data[col].dtype == 'object':  # ржЯрзЗржХрзНрж╕ржЯ ржХрж▓рж╛ржо
                text_columns.append(col)
        
        # ржкрзНрж░рждрж┐ржЯрж┐ ржУрж╖рзБржзрзЗрж░ ржЬржирзНржп рж╕ржорзНржорж┐рж▓рж┐ржд ржЯрзЗржХрзНрж╕ржЯ рждрзИрж░рж┐ ржХрж░рзБржи
        self.data['combined_text'] = self.data[text_columns].fillna('').astype(str).agg(' '.join, axis=1)
        
        # ржЯрзЗржХрзНрж╕ржЯ ржкрж░рж┐рж╖рзНржХрж╛рж░ ржХрж░рзБржи
        self.data['cleaned_text'] = self.data['combined_text'].apply(self.clean_text)
        
        # TF-IDF ржнрзЗржХрзНржЯрж░рж╛ржЗржЬрж╛рж░ рждрзИрж░рж┐ ржХрж░рзБржи
        self.vectorizer = TfidfVectorizer(
            max_features=2000,
            ngram_range=(1, 3),
            min_df=1,
            stop_words=None  # ржмрж╛ржВрж▓рж╛ рж╕рзНржЯржк ржУржпрж╝рж╛рж░рзНржбрж╕ ржорзНржпрж╛ржирзБржпрж╝рж╛рж▓рж┐ рж╣рзНржпрж╛ржирзНржбрж▓ ржХрж░ржм
        )
        
        # TF-IDF ржорзНржпрж╛ржЯрзНрж░рж┐ржХрзНрж╕ рждрзИрж░рж┐ ржХрж░рзБржи
        self.tfidf_matrix = self.vectorizer.fit_transform(self.data['cleaned_text'])
    
    def clean_text(self, text):
        """ржЯрзЗржХрзНрж╕ржЯ ржкрж░рж┐рж╖рзНржХрж╛рж░ ржПржмржВ ржкрзНрж░рж┐ржкрзНрж░рж╕рзЗрж╕ ржХрж░рзБржи"""
        # рж▓рзЛржпрж╝рж╛рж░ржХрзЗрж╕ ржХрж░рзБржи
        text = text.lower()
        
        # ржмрж┐рж╢рзЗрж╖ ржХрзНржпрж╛рж░рзЗржХрзНржЯрж╛рж░ рж╕рж░рж╛ржи ржХрж┐ржирзНрждрзБ ржмрж╛ржВрж▓рж╛ ржЯрзЗржХрзНрж╕ржЯ рж░рж╛ржЦрзБржи
        text = re.sub(r'[^\w\s\u0980-\u09FF]', ' ', text)
        
        # ржЕрждрж┐рж░рж┐ржХрзНржд рж╕рзНржкрзЗрж╕ рж╕рж░рж╛ржи
        text = re.sub(r'\s+', ' ', text).strip()
        
        # ржмрж╛ржВрж▓рж╛ рж╕рзНржЯржк ржУржпрж╝рж╛рж░рзНржбрж╕ рж╕рж░рж╛ржи
        words = text.split()
        filtered_words = [word for word in words if word not in self.bengali_stop_words]
        
        return ' '.join(filtered_words)
    
    def search_all_sources(self, query, top_k=5):
        """рж╕ржм ржЙрзОрж╕ ржерзЗржХрзЗ рж╕рж╛рж░рзНржЪ ржХрж░рзБржи"""
        self.update_all_sources()
        
        if not self.all_sources:
            return []
        
        results = []
        
        for source in self.all_sources:
            # ржЯрзЗржХрзНрж╕ржЯ ржкрж░рж┐рж╖рзНржХрж╛рж░ ржХрж░рзБржи
            cleaned_content = self.clean_text(source['content'])
            cleaned_query = self.clean_text(query)
            
            # рж╕рж░рж▓ ржХрзАржУржпрж╝рж╛рж░рзНржб ржорзНржпрж╛ржЪрж┐ржВ
            query_words = cleaned_query.split()
            content_words = cleaned_content.split()
            
            # ржорзНржпрж╛ржЪ рж╕рзНржХрзЛрж░ ржЧржгржирж╛ ржХрж░рзБржи
            matches = sum(1 for word in query_words if word in content_words)
            if matches > 0:
                score = matches / len(query_words)
                
                # ржХржиржЯрзЗржХрзНрж╕ржЯ ржЦрзБржБржЬрзЗ ржмрзЗрж░ ржХрж░рзБржи
                context = self.extract_context(source['content'], query, 200)
                
                results.append({
                    'source': source['source'],
                    'filename': source.get('filename', source.get('url', 'Unknown')),
                    'score': score,
                    'context': context,
                    'full_content': source['content'][:500] + "..." if len(source['content']) > 500 else source['content'],
                    'upload_time': source.get('upload_time', ''),
                    'data': source.get('data', {})
                })
        
        # рж╕рзНржХрзЛрж░ ржЕржирзБржпрж╛ржпрж╝рзА рж╕рж╛ржЬрж╛ржи
        results.sort(key=lambda x: x['score'], reverse=True)
        return results[:top_k]
    
    def extract_context(self, text, query, context_length=200):
        """ржХрзЛржпрж╝рзЗрж░рж┐рж░ ржЖрж╢рзЗржкрж╛рж╢рзЗрж░ ржХржиржЯрзЗржХрзНрж╕ржЯ ржПржХрзНрж╕ржЯрзНрж░рзНржпрж╛ржХрзНржЯ ржХрж░рзБржи"""
        query_lower = query.lower()
        text_lower = text.lower()
        
        # ржХрзЛржпрж╝рзЗрж░рж┐рж░ ржкрзНрж░ржержо ржорзНржпрж╛ржЪ ржЦрзБржБржЬрзБржи
        start_pos = text_lower.find(query_lower)
        
        if start_pos == -1:
            # ржХрзЛржпрж╝рзЗрж░рж┐ рж╢ржмрзНржжржЧрзБрж▓рж┐ ржЦрзБржБржЬрзБржи
            query_words = query_lower.split()
            for word in query_words:
                pos = text_lower.find(word)
                if pos != -1:
                    start_pos = pos
                    break
        
        if start_pos == -1:
            return text[:context_length] + "..." if len(text) > context_length else text
        
        # ржХржиржЯрзЗржХрзНрж╕ржЯ ржПржХрзНрж╕ржЯрзНрж░рзНржпрж╛ржХрзНржЯ ржХрж░рзБржи
        start = max(0, start_pos - context_length // 2)
        end = min(len(text), start_pos + len(query) + context_length // 2)
        
        context = text[start:end]
        
        if start > 0:
            context = "..." + context
        if end < len(text):
            context = context + "..."
        
        return context
    
    def search_medicines(self, query, top_k=5):
        """ржкрзНрж░рж╢рзНржирзЗрж░ ржнрж┐рждрзНрждрж┐рждрзЗ ржУрж╖рзБржз ржЦрзБржБржЬрзБржи"""
        if self.data is None or self.vectorizer is None:
            return []
        
        # ржкрзНрж░рж╢рзНржи ржкрж░рж┐рж╖рзНржХрж╛рж░ ржХрж░рзБржи
        cleaned_query = self.clean_text(query)
        
        # ржкрзНрж░рж╢рзНржиржХрзЗ TF-IDF ржнрзЗржХрзНржЯрж░рзЗ рж░рзВржкрж╛ржирзНрждрж░ ржХрж░рзБржи
        query_vector = self.vectorizer.transform([cleaned_query])
        
        # рж╕рж┐ржорж┐рж▓рж╛рж░рж┐ржЯрж┐ ржЧржгржирж╛ ржХрж░рзБржи
        similarities = cosine_similarity(query_vector, self.tfidf_matrix).flatten()
        
        # рж╢рзАрж░рзНрж╖ ржорзНржпрж╛ржЪржЧрзБрж▓рж┐ ржкрж╛ржи
        top_indices = similarities.argsort()[-top_k:][::-1]
        
        results = []
        for idx in top_indices:
            if similarities[idx] > 0.05:  # ржирзНржпрзВржирждржо рж╕рж┐ржорж┐рж▓рж╛рж░рж┐ржЯрж┐ ржерзНрж░рзЗрж╢рж╣рзЛрж▓рзНржб
                medicine_info = self.data.iloc[idx].to_dict()
                medicine_info['similarity_score'] = similarities[idx]
                results.append(medicine_info)
        
        return results
    
    def get_medicine_details(self, medicine_name):
        """ржирж┐рж░рзНржжрж┐рж╖рзНржЯ ржУрж╖рзБржзрзЗрж░ ржмрж┐рж╕рзНрждрж╛рж░рж┐ржд рждржерзНржп ржкрж╛ржи"""
        if self.data is None:
            return None
        
        # ржкрзНрж░ржержорзЗ рж╕ржарж┐ржХ ржорзНржпрж╛ржЪ ржЦрзБржБржЬрзБржи
        exact_match = self.data[self.data.iloc[:, 0].str.contains(medicine_name, case=False, na=False)]
        
        if len(exact_match) > 0:
            return exact_match.iloc[0].to_dict()
        
        # рж╕ржарж┐ржХ ржорзНржпрж╛ржЪ ржирж╛ ржерж╛ржХрж▓рзЗ ржлрж╛ржЬрж┐ рж╕рж╛рж░рзНржЪ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи
        results = self.search_medicines(medicine_name, top_k=1)
        if results:
            return results[0]
        
        return None

def main():
    st.set_page_config(
        page_title="ЁЯТК ржЙржирзНржиржд ржорзЗржбрж┐рж╕рж┐ржи ржЪрзНржпрж╛ржЯржмржЯ",
        page_icon="ЁЯТК",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # ржХрж╛рж╕рзНржЯржо CSS
    st.markdown("""
    <style>
    .main-header {
        font-size: 3.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        font-weight: bold;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    .chat-container {
        background: linear-gradient(135deg, #f0f2f6 0%, #e6f3ff 100%);
        padding: 2rem;
        border-radius: 15px;
        margin: 1rem 0;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    .medicine-card {
        background: white;
        padding: 1.5rem;
        border-radius: 12px;
        margin: 1rem 0;
        border-left: 5px solid #1f77b4;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        transition: transform 0.2s;
    }
    .medicine-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 8px rgba(0,0,0,0.15);
    }
    .source-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
    }
    .upload-section {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        padding: 1.5rem;
        border-radius: 12px;
        margin: 1rem 0;
        border: 2px dashed #dee2e6;
    }
    .stButton > button {
        background: linear-gradient(45deg, #1f77b4, #2e86ab);
        color: white;
        border-radius: 25px;
        padding: 0.75rem 2rem;
        border: none;
        font-weight: bold;
        transition: all 0.3s;
    }
    .stButton > button:hover {
        background: linear-gradient(45deg, #2e86ab, #1f77b4);
        transform: translateY(-2px);
        box-shadow: 0 4px 8px rgba(0,0,0,0.2);
    }
    .search-box {
        background: white;
        padding: 1rem;
        border-radius: 10px;
        border: 2px solid #e0e0e0;
        margin: 1rem 0;
    }
    .stats-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        text-align: center;
        margin: 0.5rem 0;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # рж╣рзЗржбрж╛рж░
    st.markdown('<h1 class="main-header">ЁЯТК ржЙржирзНржиржд ржорзЗржбрж┐рж╕рж┐ржи ржЪрзНржпрж╛ржЯржмржЯ</h1>', unsafe_allow_html=True)
    st.markdown("### ЁЯОп PDF, Word, Excel, API рж╕рж╣ рж╕ржм ржЙрзОрж╕ ржерзЗржХрзЗ ржУрж╖рзБржзрзЗрж░ рждржерзНржп ржЦрзБржБржЬрзБржи!")
    
    # ржЪрзНржпрж╛ржЯржмржЯ ржЗржирж┐рж╢рж┐ржпрж╝рж╛рж▓рж╛ржЗржЬ ржХрж░рзБржи
    if 'chatbot' not in st.session_state:
        st.session_state.chatbot = AdvancedMedicineChatbot('medicine_data.xlsx')
    
    # рж╕рж╛ржЗржбржмрж╛рж░
    with st.sidebar:
        st.header("ЁЯФз ржЕрждрж┐рж░рж┐ржХрзНржд ржЕржкрж╢ржи")
        
        # ржбрзЗржЯрж╛ рждржерзНржп ржжрзЗржЦрж╛ржи
        if st.session_state.chatbot.data is not None:
            st.markdown('<div class="stats-card">', unsafe_allow_html=True)
            st.metric("ЁЯУК ржорзЛржЯ ржУрж╖рзБржз", len(st.session_state.chatbot.data))
            st.markdown('</div>', unsafe_allow_html=True)
            
            st.markdown('<div class="stats-card">', unsafe_allow_html=True)
            st.metric("ЁЯУЛ ржХрж▓рж╛ржо рж╕ржВржЦрзНржпрж╛", len(st.session_state.chatbot.data.columns))
            st.markdown('</div>', unsafe_allow_html=True)
        
        # ржЗржЙржирж┐ржлрж╛ржЗржб ржЖржкрж▓рзЛржб рж╕рзЗржХрж╢ржи
        st.subheader("ЁЯУБ рж╕ржм ржлрж╛ржЗрж▓ ржЖржкрж▓рзЛржб ржХрж░рзБржи")
        st.markdown('<div class="upload-section">', unsafe_allow_html=True)
        
        # ржЯрзНржпрж╛ржм рж╕рж┐рж╕рзНржЯрзЗржо
        tab1, tab2, tab3, tab4 = st.tabs(["ЁЯУД PDF", "ЁЯУЭ Word", "ЁЯУК Excel", "ЁЯМР API"])
        
        with tab1:
            st.write("**PDF ржлрж╛ржЗрж▓ ржЖржкрж▓рзЛржб ржХрж░рзБржи**")
            pdf_file = st.file_uploader("PDF ржлрж╛ржЗрж▓ ржирж┐рж░рзНржмрж╛ржЪржи ржХрж░рзБржи", type=['pdf'], key="pdf_upload")
            if pdf_file:
                if st.button("ЁЯУД PDF ржпрзЛржЧ ржХрж░рзБржи", key="add_pdf"):
                    st.session_state.chatbot.add_pdf_file(pdf_file)
        
        with tab2:
            st.write("**Word ржлрж╛ржЗрж▓ ржЖржкрж▓рзЛржб ржХрж░рзБржи**")
            word_file = st.file_uploader("Word ржлрж╛ржЗрж▓ ржирж┐рж░рзНржмрж╛ржЪржи ржХрж░рзБржи", type=['docx', 'doc'], key="word_upload")
            if word_file:
                if st.button("ЁЯУЭ Word ржпрзЛржЧ ржХрж░рзБржи", key="add_word"):
                    st.session_state.chatbot.add_word_file(word_file)
        
        with tab3:
            st.write("**Excel ржлрж╛ржЗрж▓ ржЖржкрж▓рзЛржб ржХрж░рзБржи**")
            excel_file = st.file_uploader("Excel ржлрж╛ржЗрж▓ ржирж┐рж░рзНржмрж╛ржЪржи ржХрж░рзБржи", type=['xlsx', 'xls'], key="excel_upload")
            if excel_file:
                if st.button("ЁЯУК Excel ржпрзЛржЧ ржХрж░рзБржи", key="add_excel"):
                    st.session_state.chatbot.add_excel_file(excel_file)
        
        with tab4:
            st.write("**API рж╕ржВржпрзЛржЧ ржХрж░рзБржи**")
            api_url = st.text_input("API URL:", placeholder="https://api.example.com/medicines", key="api_url")
            api_key = st.text_input("API Key (ржРржЪрзНржЫрж┐ржХ):", type="password", placeholder="your-api-key", key="api_key")
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ЁЯФЧ API ржпрзЛржЧ ржХрж░рзБржи", key="add_api") and api_url:
                    st.session_state.chatbot.add_api_data(api_url, api_key)
            with col2:
                if st.button("ЁЯЧСя╕П рж╕ржм ржорзБржЫрзБржи", key="clear_all"):
                    st.session_state.chatbot.pdf_data = []
                    st.session_state.chatbot.word_data = []
                    st.session_state.chatbot.excel_data = []
                    st.session_state.chatbot.api_data = []
                    st.success("тЬЕ рж╕ржм ржбрзЗржЯрж╛ ржорзБржЫрзЗ ржлрзЗрж▓рж╛ рж╣ржпрж╝рзЗржЫрзЗ")
        
        st.markdown('</div>', unsafe_allow_html=True)
        
        # ржЖржкрж▓рзЛржб ржХрж░рж╛ ржлрж╛ржЗрж▓ ржжрзЗржЦрж╛ржи
        if (st.session_state.chatbot.pdf_data or st.session_state.chatbot.word_data or 
            st.session_state.chatbot.excel_data or st.session_state.chatbot.api_data):
            st.subheader("ЁЯУЛ ржЖржкрж▓рзЛржб ржХрж░рж╛ ржлрж╛ржЗрж▓")
            
            for pdf in st.session_state.chatbot.pdf_data:
                st.info(f"ЁЯУД {pdf['filename']} ({pdf['upload_time']})")
            
            for word in st.session_state.chatbot.word_data:
                st.info(f"ЁЯУЭ {word['filename']} ({word['upload_time']})")
            
            for excel in st.session_state.chatbot.excel_data:
                st.info(f"ЁЯУК {excel['filename']} ({excel['upload_time']})")
            
            for api in st.session_state.chatbot.api_data:
                st.info(f"ЁЯМР {api['url']} ({api['upload_time']})")
        
        # ржирж┐рж░рзНржжрж┐рж╖рзНржЯ ржУрж╖рзБржз ржЦрзБржБржЬрзБржи
        st.subheader("ЁЯФН ржирж┐рж░рзНржжрж┐рж╖рзНржЯ ржУрж╖рзБржз ржЦрзБржБржЬрзБржи")
        specific_medicine = st.text_input("ржУрж╖рзБржзрзЗрж░ ржирж╛ржо рж▓рж┐ржЦрзБржи:", placeholder="ржпрзЗржоржи: Paracetamol")
        
        col1, col2 = st.columns(2)
        with col1:
            search_specific = st.button("ЁЯФН ржЦрзБржБржЬрзБржи")
        with col2:
            clear_specific = st.button("ЁЯЧСя╕П ржорзБржЫрзБржи")
        
        if search_specific and specific_medicine:
            result = st.session_state.chatbot.get_medicine_details(specific_medicine)
            if result:
                st.success("тЬЕ ржУрж╖рзБржз ржкрж╛ржУржпрж╝рж╛ ржЧрзЗржЫрзЗ!")
                st.markdown('<div class="medicine-card">', unsafe_allow_html=True)
                for key, value in result.items():
                    if key not in ['combined_text', 'cleaned_text', 'similarity_score']:
                        st.write(f"**{key}:** {value}")
                st.markdown('</div>', unsafe_allow_html=True)
            else:
                st.warning("тЭМ ржУрж╖рзБржз ржкрж╛ржУржпрж╝рж╛ ржпрж╛ржпрж╝ржирж┐")
        
        if clear_specific:
            st.rerun()
    
    # ржорзВрж▓ ржЪрзНржпрж╛ржЯ ржЗржирзНржЯрж╛рж░ржлрзЗрж╕
    st.markdown('<div class="chat-container">', unsafe_allow_html=True)
    
    # рж╕рж╛рж░рзНржЪ ржЯрж╛ржЗржк ржирж┐рж░рзНржмрж╛ржЪржи
    search_type = st.radio(
        "ЁЯФН рж╕рж╛рж░рзНржЪ ржЯрж╛ржЗржк ржирж┐рж░рзНржмрж╛ржЪржи ржХрж░рзБржи:",
        ["ЁЯУК ржорзВрж▓ Excel ржбрзЗржЯрж╛", "ЁЯМР рж╕ржм ржЙрзОрж╕ (PDF/Word/Excel/API)"],
        horizontal=True
    )
    
    # ржЪрзНржпрж╛ржЯ рж╣рж┐рж╕рзНржЯрж░рж┐
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    
    # ржЪрзНржпрж╛ржЯ рж╣рж┐рж╕рзНржЯрж░рж┐ ржжрзЗржЦрж╛ржи
    for message in st.session_state.chat_history:
        if message['type'] == 'user':
            st.markdown(f"**ЁЯСд ржЖржкржирж┐:** {message['content']}")
        else:
            st.markdown(f"**ЁЯдЦ ржЪрзНржпрж╛ржЯржмржЯ:** {message['content']}")
    
    # ржмрзНржпржмрж╣рж╛рж░ржХрж╛рж░рзАрж░ ржЗржиржкрзБржЯ
    st.markdown('<div class="search-box">', unsafe_allow_html=True)
    user_query = st.text_input("ржЖржкржирж╛рж░ ржкрзНрж░рж╢рзНржи рж▓рж┐ржЦрзБржи:", placeholder="ржпрзЗржоржи: ржЬрзНржмрж░рзЗрж░ ржУрж╖рзБржз ржХрж┐ ржХрж┐ ржЖржЫрзЗ?")
    st.markdown('</div>', unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns([1, 1, 2])
    with col1:
        search_button = st.button("ЁЯФН ржЦрзБржБржЬрзБржи")
    with col2:
        clear_button = st.button("ЁЯЧСя╕П ржЪрзНржпрж╛ржЯ ржорзБржЫрзБржи")
    with col3:
        st.markdown("ЁЯТб **ржкрж░рж╛ржорж░рзНрж╢:** ржУрж╖рзБржзрзЗрж░ ржирж╛ржо, ржЙржкржХрж╛рж░рж┐рждрж╛, ржкрж╛рж░рзНрж╢рзНржмржкрзНрж░рждрж┐ржХрзНрж░рж┐ржпрж╝рж╛ рж╕ржорзНржкрж░рзНржХрзЗ ржЬрж┐ржЬрзНржЮрж╛рж╕рж╛ ржХрж░рзБржи")
    
    if clear_button:
        st.session_state.chat_history = []
        st.rerun()
    
    if search_button and user_query:
        # ржмрзНржпржмрж╣рж╛рж░ржХрж╛рж░рзАрж░ ржмрж╛рж░рзНрждрж╛ рж╣рж┐рж╕рзНржЯрж░рж┐рждрзЗ ржпрзЛржЧ ржХрж░рзБржи
        st.session_state.chat_history.append({
            'type': 'user',
            'content': user_query
        })
        
        if search_type == "ЁЯУК ржорзВрж▓ Excel ржбрзЗржЯрж╛":
            # рж╢рзБржзрзБ ржорзВрж▓ Excel ржбрзЗржЯрж╛ ржерзЗржХрзЗ рж╕рж╛рж░рзНржЪ
            results = st.session_state.chatbot.search_medicines(user_query, top_k=3)
            
            if results:
                response = "ЁЯФН ржЖржкржирж╛рж░ ржкрзНрж░рж╢рзНржирзЗрж░ ржЬржирзНржп ржирж┐ржорзНржирж▓рж┐ржЦрж┐ржд ржУрж╖рзБржзржЧрзБрж▓рж┐ ржкрж╛ржУржпрж╝рж╛ ржЧрзЗржЫрзЗ:\n\n"
                
                for i, result in enumerate(results, 1):
                    response += f"**{i}. {result.get(list(result.keys())[0], 'Unknown Medicine')}**\n"
                    
                    # ржорзВрж▓ рждржерзНржп ржпрзЛржЧ ржХрж░рзБржи
                    for key, value in result.items():
                        if key not in ['combined_text', 'cleaned_text', 'similarity_score'] and pd.notna(value) and str(value).strip():
                            response += f"   тАв **{key}:** {value}\n"
                    
                    response += f"   тАв **ржорж┐рж▓рзЗрж░ рж╣рж╛рж░:** {result.get('similarity_score', 0):.1%}\n\n"
            else:
                response = """тЭМ ржжрзБржГржЦрж┐ржд, ржЖржкржирж╛рж░ ржкрзНрж░рж╢рзНржирзЗрж░ рж╕рж╛ржерзЗ ржорж┐рж▓рзЗ ржПржоржи ржХрзЛржи ржУрж╖рзБржз ржкрж╛ржУржпрж╝рж╛ ржпрж╛ржпрж╝ржирж┐ред

ЁЯТб **ржкрж░рж╛ржорж░рзНрж╢:**
тАв ржнрж┐ржирзНржи рж╢ржмрзНржж ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ ржЪрзЗрж╖рзНржЯрж╛ ржХрж░рзБржи
тАв ржУрж╖рзБржзрзЗрж░ рж╕рж╛ржзрж╛рж░ржг ржирж╛ржо ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи
тАв ржЗржВрж░рзЗржЬрж┐ ржмрж╛ ржмрж╛ржВрж▓рж╛ ржЙржнржпрж╝ ржнрж╛рж╖рж╛ржпрж╝ ржЪрзЗрж╖рзНржЯрж╛ ржХрж░рзБржи"""
        
        else:
            # рж╕ржм ржЙрзОрж╕ ржерзЗржХрзЗ рж╕рж╛рж░рзНржЪ
            results = st.session_state.chatbot.search_all_sources(user_query, top_k=5)
            
            if results:
                response = "ЁЯФН рж╕ржм ржЙрзОрж╕ ржерзЗржХрзЗ ржЖржкржирж╛рж░ ржкрзНрж░рж╢рзНржирзЗрж░ ржлрж▓рж╛ржлрж▓:\n\n"
                
                for i, result in enumerate(results, 1):
                    source_icon = {
                        'Main Excel': 'ЁЯУК',
                        'Uploaded Excel': 'ЁЯУК',
                        'PDF': 'ЁЯУД',
                        'Word': 'ЁЯУЭ',
                        'API': 'ЁЯМР'
                    }.get(result['source'], 'ЁЯУД')
                    
                    response += f"**{i}. {source_icon} {result['source']} - {result['filename']}**\n"
                    response += f"   тАв **рж╕рзНржХрзЛрж░:** {result['score']:.1%}\n"
                    response += f"   тАв **ржХржиржЯрзЗржХрзНрж╕ржЯ:** {result['context']}\n"
                    
                    if result['data']:
                        response += "   тАв **рждржерзНржп:**\n"
                        for key, value in result['data'].items():
                            if pd.notna(value) and str(value).strip():
                                response += f"     - {key}: {value}\n"
                    
                    response += "\n"
            else:
                response = """тЭМ ржжрзБржГржЦрж┐ржд, ржХрзЛржи ржЙрзОрж╕ ржерзЗржХрзЗ ржЖржкржирж╛рж░ ржкрзНрж░рж╢рзНржирзЗрж░ рж╕рж╛ржерзЗ ржорж┐рж▓рзЗ ржПржоржи рждржерзНржп ржкрж╛ржУржпрж╝рж╛ ржпрж╛ржпрж╝ржирж┐ред

ЁЯТб **ржкрж░рж╛ржорж░рзНрж╢:**
тАв PDF, Word, Excel ржлрж╛ржЗрж▓ ржмрж╛ API ржпрзЛржЧ ржХрж░рзБржи
тАв ржнрж┐ржирзНржи рж╢ржмрзНржж ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ ржЪрзЗрж╖рзНржЯрж╛ ржХрж░рзБржи
тАв ржЗржВрж░рзЗржЬрж┐ ржмрж╛ ржмрж╛ржВрж▓рж╛ ржЙржнржпрж╝ ржнрж╛рж╖рж╛ржпрж╝ ржЪрзЗрж╖рзНржЯрж╛ ржХрж░рзБржи"""
        
        # ржмржЯрзЗрж░ ржЙрждрзНрждрж░ рж╣рж┐рж╕рзНржЯрж░рж┐рждрзЗ ржпрзЛржЧ ржХрж░рзБржи
        st.session_state.chat_history.append({
            'type': 'bot',
            'content': response
        })
        
        st.rerun()
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    # ржлрзБржЯрж╛рж░
    st.markdown("---")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.markdown("**ЁЯТК рж╕рзНржмрж╛рж╕рзНржерзНржп рж╕рзБрж░ржХрзНрж╖рж╛**")
        st.markdown("рж╕ржарж┐ржХ ржУрж╖рзБржз ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи")
    with col2:
        st.markdown("**ЁЯФН рж╕рзНржорж╛рж░рзНржЯ рж╕рж╛рж░рзНржЪ**")
        st.markdown("рж╕ржм ржЙрзОрж╕ ржерзЗржХрзЗ рждржерзНржп")
    with col3:
        st.markdown("**ЁЯМР ржмрж╣рзБ ржЙрзОрж╕ рж╕ржорж░рзНржержи**")
        st.markdown("PDF, Word, Excel, API рж╕рж╣")

if __name__ == "__main__":
    main()
